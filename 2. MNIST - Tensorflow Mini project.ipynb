{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP25PLpHmNg7k1Zi/I+Gd4G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ofkPIs-7frZM"},"outputs":[],"source":["from __future__ import absolute_import, division, print_function\n","import tensorflow as tf\n","import numpy as np"]},{"cell_type":"code","source":["# MNIST dataset parameters\n","num_classes = 10 # total classes (0-9 digits)\n","num_features = 784 # data features in our input (28*28 = 784)\n","\n","# Training parameters\n","learning_rate = 0.001\n","training_steps = 3000\n","batch_size = 256\n","display_step = 100\n","\n","# Neural Network parameters\n","n_hidden_1 = 128 # 1st layer number of neurons\n","n_hidden_2 = 256 # 2nd layer number of neurons"],"metadata":{"id":"3PMYtw0NgylV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare MNIST data.\n","\n","# download the dataset\n","\n","from tensorflow.keras.datasets import mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# convert to float32\n","x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n","\n","# Flatten images to 1-D vector of 784 features (28*28)\n","x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n","\n","# Normalize image values from [0, 255] ---> [0, 1]\n","x_train, x_test = x_train / 255. , x_test / 255."],"metadata":{"id":"xjQqwz-Ctbpu","executionInfo":{"status":"ok","timestamp":1753099657226,"user_tz":-330,"elapsed":798,"user":{"displayName":"Shazil Parwez","userId":"17294264299167245854"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f82e0c66-28f3-4db8-97af-61498bf01a04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["# Use tf.data API to shuffle and batch data\n","\n","train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"],"metadata":{"id":"0YQ4tfYrzC0s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# store layers weights and biases\n","# A random number generator to initialize weights\n","\n","random_normal = tf.initializers.RandomNormal()\n","\n","weights = {\n","    \"h1\": tf.Variable(random_normal([num_features, n_hidden_1])),\n","    \"h2\": tf.Variable(random_normal([n_hidden_1, n_hidden_2])),\n","    \"out\": tf.Variable(random_normal([n_hidden_2, num_classes]))\n","}\n","\n","biases = {\n","    \"b1\": tf.Variable(random_normal([n_hidden_1])),\n","    \"b2\": tf.Variable(random_normal([n_hidden_2])),\n","    \"out\": tf.Variable(random_normal([num_classes]))\n","}"],"metadata":{"id":"J8452zuc1CCQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Shape W_1: \", weights[\"h1\"].shape)\n","print(\"Shape W_2: \", weights[\"h2\"].shape)\n","print(\"Shape W_Out: \", weights[\"out\"].shape)\n","\n","print(\"Shape B_1: \", biases[\"b1\"].shape)\n","print(\"Shape B_2: \", biases[\"b2\"].shape)\n","print(\"Shape B_Out: \", biases[\"out\"].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLqSFC48-iue","executionInfo":{"status":"ok","timestamp":1753099660959,"user_tz":-330,"elapsed":35,"user":{"displayName":"Shazil Parwez","userId":"17294264299167245854"}},"outputId":"023dd3f7-2a47-40e0-f0f6-bad4554d64a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape W_1:  (784, 128)\n","Shape W_2:  (128, 256)\n","Shape W_Out:  (256, 10)\n","Shape B_1:  (128,)\n","Shape B_2:  (256,)\n","Shape B_Out:  (10,)\n"]}]},{"cell_type":"code","source":["# Create model\n","\n","def neural_net(x):\n","  # Hidden fully connected layer with 128 neuron.\n","\n","  layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1']) # Z1\n","\n","  # Apply sigmoid to layer_1 output for non-linearity\n","\n","  layer_1 = tf.nn.sigmoid(layer_1)\n","\n","\n","\n","  # Hidden fully connected layer with 256 neurons.\n","\n","  layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']) # Z2\n","\n","  # apply sigmoid to layer_2 output\n","\n","  layer_2 = tf.nn.sigmoid(layer_2) # A2\n","\n","\n","\n","  # Output fully connected layer with a neuron for each class --> 10\n","\n","  out_layer = tf.matmul(layer_2, weights['out']) + biases['out'] # Z3\n","\n","  # Apply softmax to normalize the logits to a probability distributions\n","\n","  return tf.nn.softmax(out_layer)"],"metadata":{"id":"mPtZM-BW_ezT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cross-Entropy loss function\n","def cross_entropy(y_pred, y_true):\n","  # Encode label to a one hot vector\n","  y_true = tf.one_hot(y_true, depth = num_classes)\n","\n","  # Clip predictions values to avoid log(0) error.\n","\n","  y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n","\n","  # Compute cross-entropy loss\n","\n","  return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n","\n","# Accuracy metrics\n","def accuracy(y_pred, y_true):\n","  # Predicted class is the index of highest score in prediction vector( ie argmax)\n","  correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n","  return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis = -1)\n","\n","# Stochastic gradient descent optimizer\n","optimizer = tf.optimizers.SGD(learning_rate)"],"metadata":{"id":"c1Jryr-2qaC0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optimizing process\n","def run_optimization(x, y):\n","  # Wrap computation inside a GradientTape for automatic differentiation\n","\n","  with tf.GradientTape() as g:\n","    pred = neural_net(x)\n","    loss = cross_entropy(pred, y)\n","\n","  # Variable to update ie trainable during back propagation\n","\n","  trainable_variables = list(weights.values()) + list(biases.values())\n","\n","  # Compute gradients\n","  gradients = g.gradient(loss, trainable_variables)\n","\n","  # Update W and b following gradients\n","  optimizer.apply_gradients(zip(gradients, trainable_variables))"],"metadata":{"id":"ES0ku5rpQ9o_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run training for the given number of steps\n","for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n","  # Run the optimization to update W and b values after ecah batch\n","  run_optimization(batch_x, batch_y)\n","\n","  if step % display_step == 0:\n","    pred = neural_net(batch_x)\n","    loss = cross_entropy(pred, batch_y)\n","    acc = accuracy(pred, batch_y)\n","\n","    print(f\"step: {step}, loss: {loss}, accuracy: {acc}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VB3dF_3OydVA","executionInfo":{"status":"ok","timestamp":1753099716159,"user_tz":-330,"elapsed":45441,"user":{"displayName":"Shazil Parwez","userId":"17294264299167245854"}},"outputId":"343aef8c-572d-42a3-f4db-75aea3b344c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["step: 100, loss: 564.4542846679688, accuracy: 0.27734375\n","step: 200, loss: 400.43096923828125, accuracy: 0.5625\n","step: 300, loss: 247.0797576904297, accuracy: 0.6953125\n","step: 400, loss: 189.78338623046875, accuracy: 0.80078125\n","step: 500, loss: 139.92044067382812, accuracy: 0.84765625\n","step: 600, loss: 141.63168334960938, accuracy: 0.828125\n","step: 700, loss: 89.343017578125, accuracy: 0.91796875\n","step: 800, loss: 122.954833984375, accuracy: 0.859375\n","step: 900, loss: 87.2774429321289, accuracy: 0.9140625\n","step: 1000, loss: 89.26688385009766, accuracy: 0.9140625\n","step: 1100, loss: 65.14659881591797, accuracy: 0.9296875\n","step: 1200, loss: 75.53355407714844, accuracy: 0.9296875\n","step: 1300, loss: 92.92730712890625, accuracy: 0.90234375\n","step: 1400, loss: 58.568214416503906, accuracy: 0.9453125\n","step: 1500, loss: 67.79147338867188, accuracy: 0.94140625\n","step: 1600, loss: 91.46562194824219, accuracy: 0.89453125\n","step: 1700, loss: 65.04832458496094, accuracy: 0.953125\n","step: 1800, loss: 79.53193664550781, accuracy: 0.8984375\n","step: 1900, loss: 67.58016967773438, accuracy: 0.921875\n","step: 2000, loss: 66.56582641601562, accuracy: 0.92578125\n","step: 2100, loss: 54.840179443359375, accuracy: 0.94140625\n","step: 2200, loss: 68.23612213134766, accuracy: 0.9375\n","step: 2300, loss: 50.78585433959961, accuracy: 0.953125\n","step: 2400, loss: 49.700111389160156, accuracy: 0.9296875\n","step: 2500, loss: 54.81428909301758, accuracy: 0.94921875\n","step: 2600, loss: 80.74917602539062, accuracy: 0.90625\n","step: 2700, loss: 61.490516662597656, accuracy: 0.921875\n","step: 2800, loss: 30.350719451904297, accuracy: 0.96875\n","step: 2900, loss: 52.4354248046875, accuracy: 0.93359375\n","step: 3000, loss: 55.91709518432617, accuracy: 0.9375\n"]}]},{"cell_type":"code","source":["# Test model on validation set\n","\n","pred = neural_net(x_test)\n","\n","print(f\"Test accurcay: {accuracy(pred, y_test)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rmtv485C5KGX","executionInfo":{"status":"ok","timestamp":1753099725768,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shazil Parwez","userId":"17294264299167245854"}},"outputId":"23f908ca-48f9-4ced-e275-7322c5f6ccc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accurcay: 0.9368000030517578\n"]}]},{"cell_type":"code","source":["# Visual prediction comparison\n","\n","import matplotlib.pyplot as plt"],"metadata":{"id":"FESslnWV7b7d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict 5 images from the validation set\n","n_images = 1000\n","\n","test_images = x_test[:n_images]\n","# Shape = [5, 784]\n","\n","predictions = neural_net(test_images)\n","# [5, 10]\n","\n","# Display image and model prediction\n","for i in range(n_images):\n","  plt.imshow(np.reshape(test_images[i], [28, 28]), cmap = 'grey')\n","  plt.show()\n","  print(f\"Model prediction {np.argmax(predictions. numpy()[i])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Mzri4_CKNR2zszYykJCUP5H_GVF81vPA"},"id":"apzt-lBF703u","executionInfo":{"status":"ok","timestamp":1753100703433,"user_tz":-330,"elapsed":149253,"user":{"displayName":"Shazil Parwez","userId":"17294264299167245854"}},"outputId":"27406c32-2aab-42b9-ee80-db42d275210d"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"vZVC71y38uUz"},"execution_count":null,"outputs":[]}]}